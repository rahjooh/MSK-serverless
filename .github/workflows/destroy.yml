name: Destroy

on:
  workflow_dispatch:

permissions:
  contents: read

concurrency:
  group: terraform-${{ github.ref }}
  cancel-in-progress: false

env:
  TERRAFORM_VERSION: 1.6.6
  TF_WORKING_DIR: .
  TF_VARS_FILE: ci.auto.tfvars
  TF_BACKEND_FILE: backend.auto.tfbackend
  AWS_REGION: ${{ vars.AWS_REGION || '' }}
  TF_BACKEND_BUCKET: ${{ vars.TF_BACKEND_BUCKET || vars.S3_BUCKET || '' }}
  TF_BACKEND_REGION: ${{ vars.TF_BACKEND_REGION || vars.AWS_REGION || '' }}
  TF_BACKEND_KEY: ${{ vars.TF_BACKEND_KEY || '' }}
  S3_BUCKET: ${{ vars.S3_BUCKET || '' }}

jobs:
  destroy:
    name: Destroy infrastructure
    runs-on: ubuntu-latest
    environment:
      name: production
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: ${{ env.TERRAFORM_VERSION }}

      - name: Load Terraform configuration
        run: python3 scripts/load_terraform_config.py
        env:
          TERRAFORM_TFVARS: ${{ secrets.TERRAFORM_TFVARS }}

      - name: Ensure AWS access keys are provided
        run: |
          set -euo pipefail
          missing=0
          for var in AWS_ACCESS_KEY_ID AWS_SECRET_ACCESS_KEY; do
            if [ -z "${!var:-}" ]; then
              echo "::error::Missing $var secret. Add it to the repository or environment secrets.";
              missing=1
            fi
          done
          if [ "$missing" -ne 0 ]; then
            exit 1
          fi
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}

      - name: Validate backend config (skip invalid)
        if: ${{ hashFiles(env.TF_BACKEND_FILE) != '' }}
        run: |
          set -euo pipefail
          FILE="${TF_BACKEND_FILE}"
          # Consider the file invalid if it lacks bucket/key assignments
          if ! grep -Eq '^[[:space:]]*(bucket|key)[[:space:]]*=' "$FILE"; then
            echo "::notice::Invalid backend config in $FILE; removing so init can use default/backend args."
            rm -f "$FILE"
          fi

      - name: Read backend from versions.tf (fallback)
        if: ${{ hashFiles(env.TF_BACKEND_FILE) == '' }}
        run: |
          python3 - <<'PY'
          import os, re, sys
          workdir = os.environ.get('TF_WORKING_DIR', '.') or '.'
          path = os.path.join(workdir, 'versions.tf')
          if not os.path.isfile(path):
              sys.exit(0)
          content = open(path, 'r', encoding='utf-8').read()
          # Find backend "s3" block
          m = re.search(r'backend\s+"s3"\s*\{', content)
          if not m:
              sys.exit(0)
          i = m.end()
          depth = 1
          kv = {}
          while i < len(content) and depth > 0:
              ch = content[i]
              if ch == '{':
                  depth += 1
              elif ch == '}':
                  depth -= 1
              i += 1
              if depth == 0:
                  break
          block = content[m.end():i-1]
          for line in block.splitlines():
              line = line.split('#',1)[0].strip()
              if not line or '=' not in line:
                  continue
              k, v = line.split('=', 1)
              k = k.strip()
              v = v.strip().strip('"')
              if k in {'bucket','key','region'}:
                  kv[k] = v
          env_path = os.environ.get('GITHUB_ENV')
          if env_path:
              with open(env_path, 'a', encoding='utf-8') as fh:
                  if 'bucket' in kv:
                      fh.write(f"TF_BACKEND_BUCKET={kv['bucket']}\n")
                  if 'key' in kv:
                      fh.write(f"TF_BACKEND_KEY={kv['key']}\n")
                  if 'region' in kv:
                      fh.write(f"TF_BACKEND_REGION={kv['region']}\n")
          PY

      - name: Avoid double assume (clear TF_VAR_assume_role_arn; override plan)
        if: ${{ env.ASSUME_ROLE_ARN != '' }}
        run: |
          {
            echo "TF_VAR_assume_role_arn<<EOF";
            echo "";
            echo "EOF";
            # Ensure any terraform plan invocations ignore assume_role_arn from tfvars
            echo "TF_CLI_ARGS_plan=-var=assume_role_arn=\"\"";
          } >> "$GITHUB_ENV"

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-session-token: ${{ secrets.AWS_SESSION_TOKEN }}
          aws-region: ${{ env.TF_BACKEND_REGION || env.AWS_REGION_EFFECTIVE || env.AWS_REGION || secrets.AWS_REGION }}
          role-to-assume: ${{ env.ASSUME_ROLE_ARN || '' }}
          role-duration-seconds: ${{ env.ASSUME_ROLE_ARN != '' && '3600' || '' }}
          role-skip-session-tagging: true

      - name: Validate AWS credential configuration
        if: ${{ env.ASSUME_ROLE_ARN == '' }}
        run: |
          echo "::error::Set assume_role_arn in the TERRAFORM_TFVARS secret so the workflow can assume AWS credentials."
          exit 1

      - name: Detect backend bucket region
        if: ${{ env.TF_BACKEND_BUCKET != '' || hashFiles(env.TF_BACKEND_FILE) != '' }}
        run: |
          set -euo pipefail
          BUCKET="${TF_BACKEND_BUCKET:-}"
          if [ -z "${BUCKET}" ] && [ -s "${TF_BACKEND_FILE}" ]; then
            BUCKET=$(awk -F'=' '/^[[:space:]]*bucket[[:space:]]*=/{gsub(/[#].*$/,""); v=$2; gsub(/^[[:space:]]+|[[:space:]]+$/,"",v); gsub(/"/ , "", v); print v}' "${TF_BACKEND_FILE}" || true)
          fi
          if [ -n "${BUCKET}" ]; then
            REGION=$(aws s3api get-bucket-location --bucket "${BUCKET}" --query 'LocationConstraint' --output text 2>/dev/null || true)
            if [ "${REGION}" = "None" ] || [ -z "${REGION}" ]; then REGION="${AWS_REGION_EFFECTIVE:-${AWS_REGION:-us-east-1}}"; fi
            echo "TF_BACKEND_BUCKET=${BUCKET}" >> "$GITHUB_ENV"
            echo "TF_BACKEND_REGION=${REGION}" >> "$GITHUB_ENV"
          fi
          
      - name: Terraform init
        run: |
          set -euo pipefail
          WORKDIR="${{ env.TF_WORKING_DIR }}"
          REGION="${TF_BACKEND_REGION:-${AWS_REGION_EFFECTIVE:-${AWS_REGION:-}}}"
          if [ -n "${TF_BACKEND_BUCKET:-}" ] && [ -n "${TF_BACKEND_KEY:-}" ]; then
            ARGS=( -input=false -reconfigure \
              "-backend-config=bucket=${TF_BACKEND_BUCKET}" \
              "-backend-config=key=${TF_BACKEND_KEY}" )
            if [ -n "${REGION}" ]; then ARGS+=( "-backend-config=region=${REGION}" ); fi
            terraform -chdir="${WORKDIR}" init "${ARGS[@]}"
          elif [ -s "${TF_BACKEND_FILE}" ]; then
            if [ -n "${REGION}" ]; then
              terraform -chdir="${WORKDIR}" init -input=false -backend-config="${TF_BACKEND_FILE}" -backend-config="region=${REGION}"
            else
              terraform -chdir="${WORKDIR}" init -input=false -backend-config="${TF_BACKEND_FILE}"
            fi
          else
            terraform -chdir="${WORKDIR}" init -input=false
          fi

      - name: Check Terraform state contents
        id: state_check
        run: |
          set -eo pipefail
          if terraform -chdir=${{ env.TF_WORKING_DIR }} state list > state-list.txt; then
            if [ -s state-list.txt ]; then
              echo "empty=false" >> "$GITHUB_OUTPUT"
            else
              echo "empty=true" >> "$GITHUB_OUTPUT"
            fi
          else
            echo "empty=true" >> "$GITHUB_OUTPUT"
          fi

      - name: Rebuild Terraform state from existing infrastructure
        if: ${{ steps.state_check.outputs.empty == 'true' && env.TF_BACKEND_BUCKET != '' && env.TF_BACKEND_KEY != '' && env.TF_VAR_vpc_id != '' && env.TF_VAR_subnet_ids != '' }}
        run: bash scripts/rebuild-tfstate.sh
        env:
          TF_BACKEND_BUCKET: ${{ env.TF_BACKEND_BUCKET }}
          TF_BACKEND_KEY: ${{ env.TF_BACKEND_KEY }}
          TF_BACKEND_REGION: ${{ env.TF_BACKEND_REGION || env.AWS_REGION_EFFECTIVE || env.AWS_REGION }}
          TF_VAR_vpc_id: ${{ env.TF_VAR_vpc_id }}
          TF_VAR_subnet_ids: ${{ env.TF_VAR_subnet_ids }}
          TF_VAR_region: ${{ env.TF_VAR_region || env.AWS_REGION_EFFECTIVE || env.AWS_REGION }}
          TF_VAR_cluster_name: ${{ env.TF_VAR_cluster_name }}
          TF_VAR_collector_sg_name: ${{ env.TF_VAR_collector_sg_name }}
          TF_VAR_consumer_sg_name: ${{ env.TF_VAR_consumer_sg_name }}
          AWS_REGION: ${{ env.AWS_REGION_EFFECTIVE || env.AWS_REGION }}
          ASSUME_ROLE_ARN: ${{ env.ASSUME_ROLE_ARN }}

      - name: Terraform destroy
        run: |
          if [ -f "${{ env.TF_VARS_FILE }}" ]; then
            terraform -chdir=${{ env.TF_WORKING_DIR }} destroy -auto-approve -input=false -var=assume_role_arn="" -var-file="${{ env.TF_VARS_FILE }}"
          else
            terraform -chdir=${{ env.TF_WORKING_DIR }} destroy -auto-approve -input=false -var=assume_role_arn=""
          fi

      - name: Save post-destroy summary
        run: |
          (terraform -chdir=${{ env.TF_WORKING_DIR }} output -json infrastructure_summary_json > resources.json) \
            || printf '{}' > resources.json

      - name: Publish post-destroy summary to S3
        if: ${{ env.INFRA_SUMMARY_BUCKET != '' && env.INFRA_SUMMARY_KEY != '' }}
        run: aws s3 cp resources.json "s3://${{ env.INFRA_SUMMARY_BUCKET }}/${{ env.INFRA_SUMMARY_KEY }}"
